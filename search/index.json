[{"content":"记录一下3月24日-3月28日期间的背单词情况。\n最近一周平均每日背单词时间应该有200分钟，但因为前一周有些忙攒了很多要复习的单词，所以每天以复习为主，下周的计划是恢复之前每天100左右的新词学习量，争取在下一周把单词全部背完！\n","date":"2025-03-28T18:40:58+08:00","permalink":"https://Savannah99.github.io/p/myfirstblog-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%91%A8/","title":"MyFirstBlog-背单词记录第一周"},{"content":"《Equivariant Multi-Modality Image Fusion》(CVPR 2024) 阅读笔记 持续更新ing\u0026hellip;具体使用的方法了解了个大概，之后在继续补充细节\n动机 多模态图像融合（如红外-可见光、医学图像融合）旨在结合不同传感器的互补信息（如热辐射和纹理细节），生成信息更全面的融合图像。然而，这一任务面临两大挑战：\n缺乏真实标签数据：现实中不存在能够同时捕获所有模态信息的\u0026quot;超级传感器\u0026quot;，导致无法通过监督学习直接训练模型。\n传统方法的局限性：\n生成模型（如GAN）依赖分布对齐，但训练不稳定且缺乏解释性\n手工设计的损失函数（如直接最小化融合图像与源图像的L1/L2距离）忽略了不同模态的特征空间差异，可能导致融合结果失真\n现有方法过度依赖对融合图像的先验假设（如低秩、稀疏性），但这些假设在真实场景中可能失效\n因此，作者提出从自然成像系统的等变性先验出发，构建自监督学习框架，避免依赖人工标注数据或强假设。\n多模态图像融合详解 1. 多模态图像融合的定义 多模态图像融合（如红外-可见光、医学图像融合）通过结合不同传感器的互补信息（如红外传感器捕获的热辐射和可见光相机捕捉的纹理细节），生成一张信息更全面的融合图像。其核心目标是整合不同模态的优势，解决单一传感器的局限性。\n2. 不同传感器及其成像特点 传感器类型 成像原理 图像特点 应用场景 可见光相机 捕捉物体反射的可见光（400-700nm） 高分辨率、色彩丰富、依赖光照 白天监控、人脸识别 红外传感器 捕捉物体热辐射（3μm-14μm） 无色彩、显示温度差异、穿透烟雾 夜间监控、火灾监测 X射线 穿透物体后检测能量衰减 显示骨骼结构、低软组织对比度 骨折诊断、工业探伤 MRI（磁共振） 利用磁场和射频脉冲成像 高软组织对比度、无辐射 脑部肿瘤检测、关节病变诊断 超声波 声波反射成像 实时动态、无辐射但分辨率较低 胎儿监测、心血管检查 图像差异对比：\n医学场景：MRI显示软组织细节（如脑肿瘤），X射线显示骨骼结构，融合后可同时观察肿瘤位置与骨骼关系。 3. 多模态图像融合的目标是生成一张整合多模态信息的图像 例如：\n红外-可见光融合图像：同时保留热辐射（暗光目标）和纹理细节（边缘清晰度）。 医学影像融合（MRI-PET）：结合解剖结构（MRI）和代谢活动（PET），辅助癌症诊断。 优势：\n互补性：解决单一模态的缺陷（如可见光依赖光照、红外缺乏细节）。 增强信息量：在复杂环境（夜间、烟雾）中提供更全面的感知。 下游任务优化：提升目标检测、语义分割等任务的准确性（如夜间自动驾驶中融合红外和可见光数据）。 总结 多模态图像融合通过整合不同传感器的互补信息（如热辐射+纹理细节），生成一张信息更全面的图像。这种技术广泛应用于安防、医疗、自动驾驶等领域，是提升感知能力的关键手段。\n传统多模态图像融合方法的局限性详解 1. 生成模型（如GAN）依赖分布对齐，但训练不稳定且缺乏解释性 原理：\n生成对抗网络（GAN）通过生成器与判别器的对抗训练，迫使融合图像与源图像的分布对齐[融合图像需同时匹配红外和可见光图像的特征分布，形成联合概率分布，例如：在暗光区域，融合图像应接近红外图像的热分布；在纹理丰富区域，融合图像需接近可见光图像的纹理分布]。例如，生成器试图生成类似可见光纹理和红外热辐射的融合图像，而判别器则区分真实源图像与生成结果。\n局限性：\n训练不稳定：GAN的对抗训练容易陷入模式崩溃而生成单一结果（生成器发现某些样本能稳定欺骗判别器，陷入局部最优，如反复生成特定热目标而忽略其他特征）或梯度消失（判别器过于强大，生成器的梯度趋近于零，无法有效更新参数）。例如，在红外-可见光融合中，生成器可能仅复制可见光细节而忽略红外热目标。 缺乏解释性：GAN的生成过程是黑箱操作，难以解释融合图像如何平衡不同模态的特征。例如，医学图像融合时，无法确定病灶区域是否被准确保留。 依赖分布对齐：若源图像分布差异大（如MRI的软组织与CT的骨骼），GAN可能无法有效融合互补信息，导致关键特征丢失。 论文支撑：\n\u0026ldquo;生成模型（如GAN）缺乏解释性、可控性，且存在训练挑战\u0026rdquo;（Section 1）。\n2. 手工设计的损失函数（如L1/L2距离）忽略了特征空间差异 $$\\mathcal{L} = \\|f - i_1\\|_1 + \\|f - i_2\\|_1$$$$\\mathcal{L} = \\|f - i_1\\|_2^2 + \\|f - i_2\\|_2^2$$\n其中，$f$为融合图像，$i_1$和$i_2$为输入的红外和可见光图像。\n局限性：\n特征流形差异：不同模态的特征空间可能不重叠。例如，红外人体的热轮廓在可见光中可能对应无纹理的暗区； 可见光的道路纹理在红外中可能表现为低对比度的温度分布。强行对齐会导致融合结果失真（如热目标模糊或纹理断裂）。 信息冲突：融合图像可能被迫在矛盾特征间妥协（如平衡热目标与纹理细节），导致关键信息丢失。像素相似不代表语义对齐，例如融合图像可能在像素上平均热目标和背景，但语义上无法突出目标。 示例：\n在夜间场景中，可见光图像噪声大，红外图像显示热目标。传统$\\ell_1$损失（绝对误差损失）可能迫使融合图像在噪声区域与红外热目标之间平均，导致目标模糊或噪声被保留。\n论文支撑：\n\u0026ldquo;直接计算$$|f-i_1\\| + \\|f-i_2\\|$$忽略了融合图像与源图像的特征流形差异\u0026rdquo;（Section 1）。\n3. 现有方法过度依赖先验假设（如低秩、稀疏性） 原理：\n部分方法假设融合图像具有特定结构，如低秩（矩阵秩[^秩]低）、稀疏性（大部分系数为零）或多尺度分解（不同频段分离）。\n[^秩]：矩阵中线性无关的行或列的最大数量。计算方式是将矩阵通过初等行变换（如高斯消元法）化为行阶梯形矩阵，非零行的数量即为秩。\n局限性：\n先验失效：真实场景可能违反假设。例如： 低秩假设：复杂纹理（如城市街景）需要高秩表示，低秩约束会导致细节丢失。 稀疏性假设：连续结构（如医学图像中的血管）无法用稀疏系数描述，导致融合结果断裂。 领域依赖性：先验假设需依赖领域知识，难以泛化到新场景。例如，医学图像中的病灶可能不符合自然图像的稀疏性假设。 案例：\n在医学融合（MRI-PET）中，低秩假设可能平滑代谢活跃区域（PET高亮[^PET]），而稀疏性假设会忽略连续的解剖结构（MRI软组织[^MRI]）。\n[^PET]：（正电子发射断层扫描，Positron Emission Tomography）是一种功能性医学成像技术，通过检测放射性示踪剂在人体内的分布，反映组织的代谢活动水平。其核心原理是： 1.示踪剂注射：患者注射含有正电子发射核素（如氟代脱氧葡萄糖，¹⁸F-FDG）的示踪剂。2.代谢追踪：示踪剂在体内参与代谢过程（如肿瘤细胞对葡萄糖的高摄取），释放正电子。3.信号检测：正电子与周围电子湮灭产生γ光子对，被PET探测器捕获，生成三维代谢活性图像。 \u0026gt;PET图像中的高亮区域（如肿瘤代谢活跃区）通常包含局部细节和动态变化信息。低秩约束会强制融合结果保留“主要结构”，导致这些高亮区域被过度平滑，代谢活动的边界模糊化。\n[^MRI]：（Magnetic Resonance Imaging，磁共振成像）是一种无创医学成像技术，利用强磁场和射频脉冲生成人体内部器官和组织的详细结构图像。其核心原理基于原子核（主要是氢原子核）在磁场中的共振特性。\u0026gt;MRI软组织（如脑灰质、血管）通常呈现连续、平滑的解剖结构。稀疏性约束会强制保留“显著边缘”，但可能忽略连续的解剖细节，导致结构断裂或缺失。\n论文支撑：\n\u0026ldquo;现有方法依赖对融合图像的先验假设（如低秩、稀疏性），但这些假设在真实场景中可能失效\u0026rdquo;（Section 1）。\n总结对比 方法 核心思想 主要问题 典型场景失效案例 生成模型（GAN） 分布对齐 训练不稳定、黑箱操作、无法处理模态分布差异 医学图像中病灶区域融合不完整 手工损失函数 最小化像素/特征距离 忽略特征流形差异、导致信息冲突或失真 夜间监控中热目标与纹理难以平衡 先验假设方法 约束融合图像结构（低秩/稀疏） 先验不符合真实场景、领域依赖性强 复杂城市街景细节丢失或医学结构断裂 论文改进：\nEMMA提出通过等变性先验（如平移、旋转不变性）和伪感知模块替代手工损失与先验假设，避免领域依赖性问题，并通过自监督学习提升泛化性（Section 3.3）。\n提出方法：EMMA框架 核心思想：利用自然图像的等变性（如平移、旋转、反射等变换不影响图像内容）设计自监督学习范式\n1. 关键模块 U-Fuser（融合模块）\n基于U-Net结构，结合Restormer（全局建模）和ResNet（局部建模）\n实现跨模态特征的高效融合\n伪感知模块\n通过U-Net学习从融合图像到源图像的映射（如红外和可见光图像）\n模拟传感器的成像过程\n等变融合模块\n确保融合图像满足等变性：对融合图像施加变换后，通过伪感知和再融合的结果应与原始变换后的图像一致 2. 训练流程 预训练伪感知模块 利用现有SOTA方法的融合结果作为伪标签 学习从融合图像到源图像的映射（损失函数为L2距离） 冻结伪感知模块，训练U-Fuser 感知损失：L(Ai(f), i) + L(Av(f), v) 等变损失：L(ft, f̂t) 3. 数学支撑 $$ \\mathcal{F}(\\mathcal{A}_i(T_g f), \\mathcal{A}_v(T_g f)) = T_g \\mathcal{F}(\\mathcal{A}_i(f), \\mathcal{A}_v(f)) $$ 该约束缩小了解空间，增强了模型对复杂场景的适应能力\n最终效果 1. 图像融合性能 数据集：红外-可见光（MSRS、RoadScene、M3FD）和医学图像（Harvard） 指标（MSRS数据集）： 指标 EN↑ SD↑ 原SOTA 6.70 43.38 EMMA 6.71 44.13 视觉效果： 同时保留热辐射信息（暗光物体）和纹理细节（边缘清晰度） 图3/4显示融合图像消除冗余信息并增强目标可见性 2. 下游任务提升 目标检测（M3FD）： mAP@0.5从82.9%提升至82.9%（保持SOTA水平） 语义分割（MSRS）： 平均IoU从63.2%提升至63.7% 3. 优势总结 无需真实标签：通过等变性先验实现自监督学习 强泛化性：直接迁移到医学图像融合无需微调 可解释性：伪感知模块显式建模成像过程 开源代码：GitHub链接 ","date":"0001-01-01T00:00:00Z","permalink":"https://Savannah99.github.io/p/","title":""}]