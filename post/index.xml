<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on LuningLee</title>
        <link>https://Savannah99.github.io/post/</link>
        <description>Recent content in Posts on LuningLee</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>LuningLee</copyright>
        <lastBuildDate>Fri, 23 May 2025 16:46:00 +0800</lastBuildDate><atom:link href="https://Savannah99.github.io/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>零碎知识点</title>
        <link>https://Savannah99.github.io/p/%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9/</link>
        <pubDate>Fri, 23 May 2025 16:46:00 +0800</pubDate>
        
        <guid>https://Savannah99.github.io/p/%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9/</guid>
        <description>&lt;h3 id=&#34;一病理标签&#34;&gt;一、病理标签
&lt;/h3&gt;&lt;h4 id=&#34;1-病理标签的作用&#34;&gt;1. 病理标签的作用
&lt;/h4&gt;&lt;p&gt;病理标签是对医学图像中病变区域的结构化标注，用于标识病灶位置、类型及严重程度，支持 AI 模型训练与临床诊断。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;病灶定位&lt;/strong&gt;：在脑部 CT 中标注出血区域边界。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分类标签&lt;/strong&gt;：区分良恶性肿瘤（如‘恶性肺结节’或‘炎性假瘤’）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分级标签&lt;/strong&gt;：癌症分期（如 TNM 分期）或者病理分级（如 Gleason 评分）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-病理标签的生成方式&#34;&gt;2. 病理标签的生成方式
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;人工标注&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;专家标注&lt;/strong&gt;：有放射科医生或病理学家手动勾画病灶区域，生成像素级掩膜（如肿瘤轮廓）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;半自动标注&lt;/strong&gt;：结合 AI 预标注与人工修正，通过标签推荐语专家审核提高效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;弱监督标注&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;文本报告关联&lt;/strong&gt;：利用诊断报告中的关键词（如“左肺上叶磨玻璃结节”）生成图像级标签，无需精确掩膜。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模态对齐&lt;/strong&gt;：通过对比学习将 CT 图像与病理文本映射到同一语义空间，自动生成粗粒度标签。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-病理标签示例&#34;&gt;3. 病理标签示例
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;二值类型&lt;/strong&gt;：简单区分“有病/无病”，如肺炎检测中的阳性/阴性标注。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多类别标签&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解剖结构&lt;/strong&gt;：标记器官位置（如肝脏左叶、右肺下叶）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;病变属性&lt;/strong&gt;：包括形态（边缘毛刺、分叶）、密度（钙化、囊变）及强化特征（均匀/不均匀强化）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;病理类型&lt;/strong&gt;：肺癌分类（腺癌、鳞癌）或者脑卒中类型（缺血性/出血性）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>研究内容</title>
        <link>https://Savannah99.github.io/p/%E7%A0%94%E7%A9%B6%E5%86%85%E5%AE%B9/</link>
        <pubDate>Fri, 23 May 2025 16:46:00 +0800</pubDate>
        
        <guid>https://Savannah99.github.io/p/%E7%A0%94%E7%A9%B6%E5%86%85%E5%AE%B9/</guid>
        <description>&lt;h3 id=&#34;知识蒸馏knowledge-distillation&#34;&gt;知识蒸馏（knowledge Distillation）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简介&lt;/strong&gt;：
模型压缩与优化，核心是将大型模型（教师网络）的知识迁移到轻量化模型（学生网络）中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;经典论文&lt;/strong&gt;：
Hinton 的 Distilling the Knowledge in a Neural Network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;个人总结&lt;/strong&gt;：
看了很多关于蒸馏的笔记，大致可概括为：学生模型网络结构可以与教师模型不同（更简单），参数数量通常比教师网络少，学生网络通过学习教师模型的输出来训练模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;为什么学生网络效果不会太差&lt;/strong&gt;：
常规预测（教师模型）由于 hard target（使用 one hot 编码如[0,1,0]）存在信息湮灭（信息湮灭：例如某个手写体 2 由于带了尾巴，被识别为 7 的概率为 0.6%，被识别为 3 的概率为 97%，导致负样本信息的丢失，模型最终只能学到很多的 2 和 3 很像，而无法学到有的 2 和 7 也很像。），学生模型使用教师模型生成的软目标（如[0.05, 0.15, 0.8]）设计目标函数（有公式推导，暂未细看），可以学习更丰富特征（我的理解是学生模型通过模仿教师模型的输出，弥补了参数少、网络结构简单带来的可学习信息量少的问题，因为教师模型的输出包含了许多信息）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可做研究&lt;/strong&gt;：
病理图像分类大模型压缩（target：研究需要突出模型压缩后的性能，具体来讲是占用空间小，但准确率损失少。Motivation：减少推理时间，便于实时检测病变；移动端轻量化部署[可能有工业落地场景才需要，只是把学生模型部署移动端缺乏学术创新性]；半监督知识蒸馏，使用人工标注数据训练教师模型，之后使用学生模型生成标注。）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：
依赖深度学习框架（PyTorch/TensorFlow），需要深度学习知识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;难点&lt;/strong&gt;：
感觉像经验科学？需要通过大量实验选择表现好的简单网络结果作为学生模型采用的网络，参数维度也是需要不断地训练找出表现较好的参数维度的设计，可能不太好解释？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：
对医学经验要求低，前期研究成本适中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据要求&lt;/strong&gt;：
不强制要求医学数据，可以使用一些公开数据集先验证学生模型的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;clip-医学应用&#34;&gt;clip 医学应用
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简介&lt;/strong&gt;：
CLIP（Contrastive Language-Image Pre-training） 是由 OpenAI 提出的多模态预训练模型，其核心思想是通过对比学习将图像和文本映射到同一高维向量空间，建立可解释的对应关系。在医学领域，CLIP 的独特价值源于其能利用自然语言监督（如影像报告）解决医学数据标注稀缺的痛点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;相关论文&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;《Xplainer: Explainable Zero-shot Diagnosis via LLM-guided CLIP》（分类与诊断 - 2024 MICCAI）&lt;/li&gt;
&lt;li&gt;《AnomalyCLIP: Object-agnostic Zero-shot Anomaly Detection》（分割与检测 2024 CVPR）&lt;/li&gt;
&lt;li&gt;《MedFusion: CLIP-guided Multimodal Synthesis for Lesion Simulation》（生成病变影响 - 2025 MICCAI）&lt;/li&gt;
&lt;li&gt;《CLIP in Medical Imaging: A Comprehensive Survey》（综述，Medical Image Analysis）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;个人总结&lt;/strong&gt;：
把医学图像用 CNN 或 Transformer 转换为高维向量（比如 512 维），把诊断报告文本使用自然语言模型转换为同维度的向量（诊断报告文本需要清洗并结构化，如提取“部位 - 病变 - 属性”三元组），对齐同一病历的图像向量和文本向量（例如让他们的余弦相似度接近 1，可以使用 InfoNCE 损失函数）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可做研究&lt;/strong&gt;：
特定的医学图像 + 文本多模态训练模型，如胸片影像 + 文本训练（target：高准确率。Motivation：自动报告生成，输入影像即可生成文本；影像分类，输入自然语言[病变属性]即可对影像分类。）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：
需处理医学影像格式（DICOM/NIFTI）和医学文本（诊断报告），有开源医学框架 PLIP、MedCLIP 可学习，需要学习图像处理模型和自然语言处理模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;难点&lt;/strong&gt;：
需要同时学习自然语言处理模型和图像处理模型，代码实现可能相对复杂，前期学习成本较高。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：
多模态是近年的热点，较为前沿。可以使用公开的医学影像数据集，如 NIH Chest X-ray Dataset（胸部 x 光片，约 112120 张，部分子集提供放射科医生的详细裁决）、LIDC-IDRI（胸部 CT，包含对结节位置、大小及良恶性的独立标注）等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据要求&lt;/strong&gt;：
一个 clip 模型可能无法适用于所有的病理图像，比如有针对肺结节的 clip 模型，有针对皮肤病变的 clip 模型，如果需要使用医生提供的数据建模，需要提前做好准备（了解病理图片的类型，文本的结构化形式，如果可以，能够在网上找到类似的开源图像更好）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;腹腔镜场景下的-3-维重建和暗区处理临床场景&#34;&gt;腹腔镜场景下的 3 维重建和暗区处理（临床场景）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;三维重建&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简介&lt;/strong&gt;：将二维医学影像通过算法重构为三维模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;个人总结&lt;/strong&gt;：目前好像已经较为成熟，有商业软件（如 Philips XperCT）落地，但针对腹腔镜手术中光照不均、运动模糊等问题还可以进行优化。可采用 U-Net 变体、Transformer 网络或生成对抗网络（GAN），学习从 2D 到 3D 的映射关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;难点&lt;/strong&gt;：
模型参数量大，实时性要求高，需要的数据量大。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据要求&lt;/strong&gt;：
需要腹腔镜影像，公开的数据集有 Cholec80（80 个腹腔镜胆囊切除手术视频）、CholecSeg8K（从 Cholec80 中提取的 8080 帧图像）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;暗区增强（Dark Area Enhancement）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt;：腹腔镜暗区增强指在腹腔镜临床场景中,因光照不足、器械遮挡、血液/烟雾干扰会形成视野盲区，增加术中误伤血管或器官的风险，以及延长手术时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;相关论文&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;《ShadowGAN: Adversarial Shadow Removal for Laparoscopic Images》（专门去除器械遮挡阴影，《MICCAI》 22）。&lt;/p&gt;
&lt;p&gt;《Shadow-Aware Dynamic Enhancement for Laparoscopic Images》（MICCAI 2023）&lt;/p&gt;
&lt;p&gt;《Swin-Transformer for Low-Light Laparoscopic Image Enhancement》（捕获长程依赖，提升血管纹理细节，IEEE Transactions on Medical Imaging (TMI),&lt;/p&gt;
&lt;p&gt;《Event-Based Vision for Surgical Robotics》（Science Robotics 2023）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;难点&lt;/strong&gt;：医学场景中，器械移动、血液流动导致暗区实时变化，且噪声种类多，例如镜面造成的反光、烟雾、运动模糊等，并且临床场景下的医学影像很难找到低光-正常光的图像对数据，只能依靠无监督学习（超低光下无监督学习生成的清晰图像可信度是否存疑？）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;个人总结&lt;/strong&gt;：经典的低光增强网络有RetinexNet和Zero-DCE，RetinexNet是监督学习，需要低光-正常光图像对，Zero-DCE是无监督学习，但对极低光场景效果有限。医学上针对不同临床场景使用的方法多样，比如在医学中，还可以利用荧光成图像标记血管指导可见光图像的暗区增强。医学场景中，对动态干扰的处理的要求高，需要对光流进行跟踪、对时序进行建模等操作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;可行的研究路径待续&#34;&gt;可行的研究路径（待续）
&lt;/h3&gt;&lt;p&gt;针对特定的病理图像数据设计 clip 模型 -&amp;gt; 对该 clip 模型进行压缩。
对开源腹腔镜手术视频数据集Cholec80进行训练，对某一时刻的暗区结合前后多帧的图像进行增强（时序网络）&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>医学影像公开数据集</title>
        <link>https://Savannah99.github.io/p/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
        <pubDate>Fri, 23 May 2025 16:46:00 +0800</pubDate>
        
        <guid>https://Savannah99.github.io/p/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE%E9%9B%86/</guid>
        <description>&lt;h4 id=&#34;一通用医学影像数据集&#34;&gt;一、&lt;code&gt;通用医学影像数据集&lt;/code&gt;
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NIH Chest X-ray Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：112,120张胸部X光片，涵盖14种肺部疾病标签（如肺炎、结节等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：部分子集提供专家标注的裁决标签（如气胸、结节等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://www.kaggle.com/datasets/nih-chest-xrays/data/&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LIDC-IDRI（肺结节数据集）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：1,018例胸部CT图像，包含4位放射科医师独立标注的结节位置、大小及良恶性信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：XML文件记录详细病变信息，支持分割与分类任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI。（注：简书上有对该数据的详解）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;BraTS（脑肿瘤分割数据集）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：多模态脑部MRI影像，标注肿瘤区域及分级标签。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：国际挑战赛标准数据，支持术前术后影像分析。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://www.kaggle.com/datasets/dschettler8845/brats-2021-task1。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HAM10000（皮肤病变数据集）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：10,000张皮肤镜图像，涵盖7种皮肤病变分类（如黑色素瘤）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;挑战&lt;/strong&gt;：数据类别存在显著不平衡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RAOS（腹部器官分割数据集）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：413个腹部CT扫描，涵盖19种器官标注。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：包含术后复杂案例，由肿瘤学家手动标注。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据集及模型地址&lt;/strong&gt;：https://github.com/Luoxd1996/RAOS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;二带有诊断报告的医学影像数据集&#34;&gt;二、带有诊断报告的医学影像数据集
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MIMIC-CXR&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：377,110张胸部X光片，每张影像对应自由文本放射学报告（含病变描述及诊断建议）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：支持多模态学习，可访问结构化标签（CSV文件）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://physionet.org/content/mimic-cxr/2.1.0/（超级大，有知乎网友评价服务器都放不下）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Lumbar-Spine MRI Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：240万份腰椎MRI扫描，附退行性疾病、椎间盘突出等诊断报告。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：支持脊柱结构分割与病理分类联合研究。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://data.mendeley.com/datasets/k57fr854j2/2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Open-i（印第安纳大学胸部X光数据集）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：7,470张胸部X光，附结构化诊断摘要及关联PubMed文献。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：支持图文检索与报告生成任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://www.selectdataset.com/dataset/31f912d96d65a4229845e01bc43449ed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Calgary Campinas 359 Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：脑部MRI扫描，用于头骨剥离与组织分割，含放射科医生报告。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://www.ccdataset.com/&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RIM-ONE DL青光眼数据集&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;内容&lt;/strong&gt;：485份眼底图像，含青光眼分类与视盘/杯分割标注。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：结合多中心数据，适用于眼科AI研究。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址&lt;/strong&gt;：https://www.kaggle.com/datasets/orvile/rim-one-retinal-dataset-for-assessing-glaucoma&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;数据集获取资源&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kaggle &amp;amp; PhysioNet&lt;/strong&gt;：提供NIH Chest X-ray、MIMIC-CXR等主流数据访问权限。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitHub开源仓库&lt;/strong&gt;：&lt;code&gt;linhandev/dataset&lt;/code&gt;整理了80+医学影像数据集及下载链接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学术竞赛数据&lt;/strong&gt;：MICCAI挑战赛发布的EndoVis（腹腔镜视频）、BraTS等。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Equivariant Multi-Modality Image Fusion(CVPR 2024) 阅读笔记</title>
        <link>https://Savannah99.github.io/p/equivariant-multi-modality-image-fusioncvpr-2024-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
        <pubDate>Sun, 30 Mar 2025 19:46:00 +0800</pubDate>
        
        <guid>https://Savannah99.github.io/p/equivariant-multi-modality-image-fusioncvpr-2024-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
        <description>&lt;p&gt;《Equivariant Multi-Modality Image Fusion》(CVPR 2024) 阅读笔记&lt;/p&gt;
&lt;p&gt;持续更新ing&amp;hellip;
3.30,了解了论文的motivation、大概的method还有效果，补充了motivation不懂的地方的知识，继续补充method部分&lt;/p&gt;
&lt;h2 id=&#34;动机&#34;&gt;动机
&lt;/h2&gt;&lt;p&gt;多模态图像融合（如红外-可见光、医学图像融合）旨在结合不同传感器的互补信息（如热辐射和纹理细节），生成信息更全面的融合图像。然而，这一任务面临两大挑战：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;缺乏真实标签数据&lt;/strong&gt;：现实中不存在能够同时捕获所有模态信息的&amp;quot;超级传感器&amp;quot;，导致无法通过监督学习直接训练模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;传统方法的局限性&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;生成模型（如GAN）依赖分布对齐，但训练不稳定且缺乏解释性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;手工设计的损失函数（如直接最小化融合图像与源图像的L1/L2距离）忽略了不同模态的特征空间差异，可能导致融合结果失真&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现有方法过度依赖对融合图像的先验假设（如低秩、稀疏性），但这些假设在真实场景中可能失效&lt;/p&gt;
&lt;p&gt;因此，作者提出从自然成像系统的&lt;strong&gt;等变性先验&lt;/strong&gt;出发，构建自监督学习框架，避免依赖人工标注数据或强假设。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;多模态图像融合详解&#34;&gt;多模态图像融合详解
&lt;/h3&gt;&lt;h4 id=&#34;1-多模态图像融合的定义&#34;&gt;&lt;strong&gt;1. 多模态图像融合的定义&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;多模态图像融合（如红外-可见光、医学图像融合）通过结合不同传感器的互补信息（如红外传感器捕获的热辐射和可见光相机捕捉的纹理细节），生成一张信息更全面的融合图像。其核心目标是整合不同模态的优势，解决单一传感器的局限性。&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;2-不同传感器及其成像特点&#34;&gt;&lt;strong&gt;2. 不同传感器及其成像特点&lt;/strong&gt;
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;传感器类型&lt;/th&gt;
          &lt;th&gt;成像原理&lt;/th&gt;
          &lt;th&gt;图像特点&lt;/th&gt;
          &lt;th&gt;应用场景&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;可见光相机&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;捕捉物体反射的可见光（400-700nm）&lt;/td&gt;
          &lt;td&gt;高分辨率、色彩丰富、依赖光照&lt;/td&gt;
          &lt;td&gt;白天监控、人脸识别&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;红外传感器&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;捕捉物体热辐射（3μm-14μm）&lt;/td&gt;
          &lt;td&gt;无色彩、显示温度差异、穿透烟雾&lt;/td&gt;
          &lt;td&gt;夜间监控、火灾监测&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;X射线&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;穿透物体后检测能量衰减&lt;/td&gt;
          &lt;td&gt;显示骨骼结构、低软组织对比度&lt;/td&gt;
          &lt;td&gt;骨折诊断、工业探伤&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;MRI（磁共振）&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;利用磁场和射频脉冲成像&lt;/td&gt;
          &lt;td&gt;高软组织对比度、无辐射&lt;/td&gt;
          &lt;td&gt;脑部肿瘤检测、关节病变诊断&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;超声波&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;声波反射成像&lt;/td&gt;
          &lt;td&gt;实时动态、无辐射但分辨率较低&lt;/td&gt;
          &lt;td&gt;胎儿监测、心血管检查&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;图像差异对比&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;医学场景&lt;/strong&gt;：MRI显示软组织细节（如脑肿瘤），X射线显示骨骼结构，融合后可同时观察肿瘤位置与骨骼关系。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;3-多模态图像融合的目标是生成一张整合多模态信息的图像&#34;&gt;&lt;strong&gt;3. 多模态图像融合的目标是生成一张整合多模态信息的图像&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;红外-可见光融合图像&lt;/strong&gt;：同时保留热辐射（暗光目标）和纹理细节（边缘清晰度）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;医学影像融合（MRI-PET）&lt;/strong&gt;：结合解剖结构（MRI）和代谢活动（PET），辅助癌症诊断。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;互补性&lt;/strong&gt;：解决单一模态的缺陷（如可见光依赖光照、红外缺乏细节）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;增强信息量&lt;/strong&gt;：在复杂环境（夜间、烟雾）中提供更全面的感知。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;下游任务优化&lt;/strong&gt;：提升目标检测、语义分割等任务的准确性（如夜间自动驾驶中融合红外和可见光数据）。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;总结&#34;&gt;&lt;strong&gt;总结&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;多模态图像融合通过整合不同传感器的互补信息（如热辐射+纹理细节），生成一张信息更全面的图像。这种技术广泛应用于安防、医疗、自动驾驶等领域，是提升感知能力的关键手段。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;传统多模态图像融合方法的局限性详解&#34;&gt;传统多模态图像融合方法的局限性详解
&lt;/h3&gt;&lt;h4 id=&#34;1-生成模型如gan依赖分布对齐但训练不稳定且缺乏解释性&#34;&gt;1. &lt;strong&gt;生成模型（如GAN）依赖分布对齐，但训练不稳定且缺乏解释性&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：&lt;br&gt;
生成对抗网络（GAN）通过生成器与判别器的对抗训练，迫使融合图像与源图像的分布对齐[融合图像需同时匹配红外和可见光图像的特征分布，形成联合概率分布，例如：在暗光区域，融合图像应接近红外图像的热分布；在纹理丰富区域，融合图像需接近可见光图像的纹理分布]。例如，生成器试图生成类似可见光纹理和红外热辐射的融合图像，而判别器则区分真实源图像与生成结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;局限性&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;训练不稳定&lt;/strong&gt;：GAN的对抗训练容易陷入模式崩溃而生成单一结果（生成器发现某些样本能稳定欺骗判别器，陷入局部最优，如反复生成特定热目标而忽略其他特征）或梯度消失（判别器过于强大，生成器的梯度趋近于零，无法有效更新参数）。例如，在红外-可见光融合中，生成器可能仅复制可见光细节而忽略红外热目标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺乏解释性&lt;/strong&gt;：GAN的生成过程是黑箱操作，难以解释融合图像如何平衡不同模态的特征。例如，医学图像融合时，无法确定病灶区域是否被准确保留。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;依赖分布对齐&lt;/strong&gt;：若源图像分布差异大（如MRI的软组织与CT的骨骼），GAN可能无法有效融合互补信息，导致关键特征丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;论文支撑&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;生成模型（如GAN）缺乏解释性、可控性，且存在训练挑战&amp;rdquo;&lt;/em&gt;（Section 1）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4 id=&#34;2-手工设计的损失函数如l1l2距离忽略了特征空间差异&#34;&gt;2. &lt;strong&gt;手工设计的损失函数（如L1/L2距离）忽略了特征空间差异&lt;/strong&gt;
&lt;/h4&gt;$$\mathcal{L} = \|f - i_1\|_1 + \|f - i_2\|_1$$$$\mathcal{L} = \|f - i_1\|_2^2 + \|f - i_2\|_2^2$$&lt;p&gt;&lt;br&gt;
其中，$f$为融合图像，$i_1$和$i_2$为输入的红外和可见光图像。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;局限性&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特征流形差异&lt;/strong&gt;：不同模态的特征空间可能不重叠。例如，红外人体的热轮廓在可见光中可能对应无纹理的暗区； 可见光的道路纹理在红外中可能表现为低对比度的温度分布。强行对齐会导致融合结果失真（如热目标模糊或纹理断裂）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;信息冲突&lt;/strong&gt;：融合图像可能被迫在矛盾特征间妥协（如平衡热目标与纹理细节），导致关键信息丢失。像素相似不代表语义对齐，例如融合图像可能在像素上平均热目标和背景，但语义上无法突出目标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;示例&lt;/strong&gt;：&lt;br&gt;
在夜间场景中，可见光图像噪声大，红外图像显示热目标。传统$\ell_1$损失（绝对误差损失）可能迫使融合图像在噪声区域与红外热目标之间平均，导致目标模糊或噪声被保留。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;论文支撑&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;直接计算$$|f-i_1\| + \|f-i_2\|$$忽略了融合图像与源图像的特征流形差异&amp;rdquo;&lt;/em&gt;（Section 1）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4 id=&#34;3-现有方法过度依赖先验假设如低秩稀疏性&#34;&gt;3. &lt;strong&gt;现有方法过度依赖先验假设（如低秩、稀疏性）&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：&lt;br&gt;
部分方法假设融合图像具有特定结构，如低秩（矩阵秩&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;低）、稀疏性（大部分系数为零）或多尺度分解（不同频段分离）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;局限性&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;先验失效&lt;/strong&gt;：真实场景可能违反假设。例如：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;低秩假设&lt;/strong&gt;：复杂纹理（如城市街景）需要高秩表示，低秩约束会导致细节丢失。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;稀疏性假设&lt;/strong&gt;：连续结构（如医学图像中的血管）无法用稀疏系数描述，导致融合结果断裂。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;领域依赖性&lt;/strong&gt;：先验假设需依赖领域知识，难以泛化到新场景。例如，医学图像中的病灶可能不符合自然图像的稀疏性假设。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;案例&lt;/strong&gt;：&lt;br&gt;
在医学融合（MRI-PET）中，低秩假设可能平滑代谢活跃区域（PET高亮&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;），而稀疏性假设会忽略连续的解剖结构（MRI软组织&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;论文支撑&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;现有方法依赖对融合图像的先验假设（如低秩、稀疏性），但这些假设在真实场景中可能失效&amp;rdquo;&lt;/em&gt;（Section 1）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4 id=&#34;总结对比&#34;&gt;总结对比
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;方法&lt;/th&gt;
          &lt;th&gt;核心思想&lt;/th&gt;
          &lt;th&gt;主要问题&lt;/th&gt;
          &lt;th&gt;典型场景失效案例&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;生成模型（GAN）&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;分布对齐&lt;/td&gt;
          &lt;td&gt;训练不稳定、黑箱操作、无法处理模态分布差异&lt;/td&gt;
          &lt;td&gt;医学图像中病灶区域融合不完整&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;手工损失函数&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;最小化像素/特征距离&lt;/td&gt;
          &lt;td&gt;忽略特征流形差异、导致信息冲突或失真&lt;/td&gt;
          &lt;td&gt;夜间监控中热目标与纹理难以平衡&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;先验假设方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;约束融合图像结构（低秩/稀疏）&lt;/td&gt;
          &lt;td&gt;先验不符合真实场景、领域依赖性强&lt;/td&gt;
          &lt;td&gt;复杂城市街景细节丢失或医学结构断裂&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;论文改进&lt;/strong&gt;：&lt;br&gt;
EMMA提出通过&lt;strong&gt;等变性先验&lt;/strong&gt;（如平移、旋转不变性）和&lt;strong&gt;伪感知模块&lt;/strong&gt;替代手工损失与先验假设，避免领域依赖性问题，并通过自监督学习提升泛化性（Section 3.3）。&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;秩是矩阵中线性无关的行或列的最大数量。计算方式是将矩阵通过初等行变换（如高斯消元法）化为行阶梯形矩阵，非零行的数量即为秩。&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;PET（正电子发射断层扫描，Positron Emission Tomography）是一种功能性医学成像技术，通过检测放射性示踪剂在人体内的分布，反映组织的代谢活动水平。其核心原理是： 1.示踪剂注射：患者注射含有正电子发射核素（如氟代脱氧葡萄糖，¹⁸F-FDG）的示踪剂。2.代谢追踪：示踪剂在体内参与代谢过程（如肿瘤细胞对葡萄糖的高摄取），释放正电子。3.信号检测：正电子与周围电子湮灭产生γ光子对，被PET探测器捕获，生成三维代谢活性图像。PET图像中的高亮区域（如肿瘤代谢活跃区）通常包含局部细节和动态变化信息。低秩约束会强制融合结果保留“主要结构”，导致这些高亮区域被过度平滑，代谢活动的边界模糊化。&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;MRI（Magnetic Resonance Imaging，磁共振成像）是一种无创医学成像技术，利用强磁场和射频脉冲生成人体内部器官和组织的详细结构图像。其核心原理基于原子核（主要是氢原子核）在磁场中的共振特性。MRI软组织（如脑灰质、血管）通常呈现连续、平滑的解剖结构。稀疏性约束会强制保留“显著边缘”，但可能忽略连续的解剖细节，导致结构断裂或缺失。&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
        </item>
        <item>
        <title>MyFirstBlog-背单词记录第一周</title>
        <link>https://Savannah99.github.io/p/myfirstblog-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%91%A8/</link>
        <pubDate>Fri, 28 Mar 2025 18:40:58 +0800</pubDate>
        
        <guid>https://Savannah99.github.io/p/myfirstblog-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%91%A8/</guid>
        <description>&lt;p&gt;记录一下3月24日-3月28日期间的背单词情况。&lt;/p&gt;
&lt;p&gt;最近一周平均每日背单词时间应该有200分钟，但因为前一周有些忙攒了很多要复习的单词，所以每天以复习为主，下周的计划是恢复之前每天100左右的新词学习量，争取在下一周把单词全部背完！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Savannah99.github.io/p/myfirstblog-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%91%A8/word.jpg&#34;
	width=&#34;863&#34;
	height=&#34;1920&#34;
	srcset=&#34;https://Savannah99.github.io/p/myfirstblog-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%91%A8/word_hu12578729101259841939.jpg 480w, https://Savannah99.github.io/p/myfirstblog-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%91%A8/word_hu10390407286539697521.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;word&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;44&#34;
		data-flex-basis=&#34;107px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
